{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:04.740917Z",
     "start_time": "2025-03-08T23:38:04.735048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests"
   ],
   "id": "72c107b2bf8242d0",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* We are going to scrape https://www.delish.com/ for recipes. ",
   "id": "d136ac4d118b2214"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:04.782156Z",
     "start_time": "2025-03-08T23:38:04.774932Z"
    }
   },
   "source": [
    "def getInfo(userRequest):\n",
    "    \"\"\"\n",
    "    This function takes the user request and converts it to a link for further actions.\n",
    "    :param userRequest: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    words = userRequest.split()\n",
    "    if len(words) == 1:\n",
    "        _url = f'https://www.delish.com/search/?q={words[0]}&type=Recipes'\n",
    "    else:\n",
    "        query = '+'.join(words)\n",
    "        _url = f'https://www.delish.com/search/?q={query}&type=Recipes'\n",
    "    return _url"
   ],
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:04.855782Z",
     "start_time": "2025-03-08T23:38:04.850274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parseInfo(_url):\n",
    "    \"\"\"\n",
    "    This function takes a link as a parameter and parses it into a BeautifulSoup object.\n",
    "    :param _url: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    page = requests.get(_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    return soup"
   ],
   "id": "2dcc05716b418640",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:04.931868Z",
     "start_time": "2025-03-08T23:38:04.924867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def getPages(soup):\n",
    "    \"\"\"\n",
    "    This function takes a BeautifulSoup object and returns a list of all pages.\n",
    "    :param soup: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href')\n",
    "        if href and 'cooking/recipe-ideas/' in href:\n",
    "            urls.append(href)\n",
    "    return urls[2:]     "
   ],
   "id": "985a730c7d20be60",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:05.078009Z",
     "start_time": "2025-03-08T23:38:05.063012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetchRecipes(urls, max_urls):\n",
    "    \"\"\"\n",
    "    This function takes a list of urls and fetches all the recipes.\n",
    "    :param urls: \n",
    "    :param max_urls: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    all_recipes = []\n",
    "\n",
    "    for index, url_part in enumerate(urls):\n",
    "        if max_urls is not None and index >= max_urls:\n",
    "            break\n",
    "        url = 'https://www.delish.com/search' + url_part\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        title = soup.find('meta', {'name': 'title'} ).get('content')\n",
    "        \n",
    "        ingredients = []\n",
    "        for li in soup.find_all('li', class_='css-s5yyu3 e12sb1171'):\n",
    "            ingredient = ' '.join(li.stripped_strings)\n",
    "            ingredients.append(ingredient)\n",
    "            \n",
    "        guides = []\n",
    "        for li in soup.select('li.css-21v28f ol > li'):\n",
    "            step_number = li.find('span', class_='e1241r8m0').get_text(strip=True)\n",
    "            step_text = ' '.join(li.stripped_strings).replace(f'Step {step_number}', '').strip()\n",
    "            guide = f'Step {step_number}: {step_text}'\n",
    "            guides.append(guide)\n",
    "            \n",
    "        img_tag = soup.find('img', {'class': 'css-0 e1g79fud0'})\n",
    "        image_url = img_tag.get('src')\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            content_type = response.headers.get('content-type', '')\n",
    "            extension = 'jpg'\n",
    "            if 'png' in content_type:\n",
    "                extension = 'png'\n",
    "            elif 'webp' in content_type:\n",
    "                extension = 'webp'\n",
    "            \n",
    "            sanitized_title = \"\".join(c if c.isalnum() else \"_\" for c in title)\n",
    "            filename = f\"recipe_{index + 1}_{sanitized_title}.{extension}\"\n",
    "            \n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                \n",
    "            try:\n",
    "                img = Image.open(filename)\n",
    "                if img.format not in [\"JPEG\", \"PNG\"]:\n",
    "                    new_filename = f\"recipe_{index + 1}_{sanitized_title}_converted.jpg\"\n",
    "                    img.convert(\"RGB\").save(new_filename, \"JPEG\")\n",
    "                    os.remove(filename)\n",
    "                    filename = new_filename\n",
    "                    img.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Invalid image: {e}\")\n",
    "                filename = None\n",
    "            all_recipes.append((ingredients, guides, filename, title, index))    \n",
    "    return all_recipes"
   ],
   "id": "d66f1f77d86da2a7",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:05.096049Z",
     "start_time": "2025-03-08T23:38:05.085049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def toDoc(ingredients, guides, filename, title, index):\n",
    "    \"\"\"\n",
    "    This function takes a list of ingredients, guides, and filename and converts it into a docx file.\n",
    "    :param ingredients: \n",
    "    :param guides: \n",
    "    :param filename: \n",
    "    :param title: \n",
    "    :param index: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    document = Document()\n",
    "    document.add_heading(title, 0).bold = True\n",
    "    \n",
    "    for ingredient in ingredients:\n",
    "        document.add_paragraph(ingredient, style='List Bullet')\n",
    "    for guide in guides:\n",
    "        document.add_paragraph(guide).alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    \n",
    "    document.add_picture(filename, width=Inches(6)).alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    document.save(f'Recipe_{index + 1}.docx')"
   ],
   "id": "59f16b0125fe01c5",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:05.166325Z",
     "start_time": "2025-03-08T23:38:05.159842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def start(request, number):\n",
    "    \"\"\"\n",
    "    This function takes the user request, the number of recipes, and enables scraping.\n",
    "    :param request: \n",
    "    :param number: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    search_url = getInfo(request)\n",
    "    search_soup = parseInfo(search_url)\n",
    "    recipe_urls = getPages(search_soup)\n",
    "    all_recipes = fetchRecipes(recipe_urls, number)\n",
    "    for recipe in all_recipes:\n",
    "        ingredients, guides, filename, title, index = recipe\n",
    "        toDoc(ingredients, guides, filename, title, index)\n",
    "    return \"Recipes generated successfully.\""
   ],
   "id": "9b1980683ecfde76",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "An example of how this mini-scraper works:",
   "id": "9abd43c875245937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T00:06:35.789110Z",
     "start_time": "2025-03-09T00:06:27.293075Z"
    }
   },
   "cell_type": "code",
   "source": "start('curry', 3)",
   "id": "bc3c57fbac15c7f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipes generated successfully.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
